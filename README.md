# UMAB-SC
My master thesis in Machine Learning

## TODO
- each experiment repeated 5 times
- save experiments on file separating the execution of the policies from computation and plotting of regrets
- add the history of switching costs to the choose_arm method
- add other policies
-- KL-UCB
-- UCYCLE
-- Thopmson Sampling
-- Thompson Sampling in epochs
-- UCB1 that takes into account switching costs
- compute theoretical bounds of each policy
- compute variance of the regrets
- plot variance and theoretical bound
- adjust file saving procedure by separating in subfolders different policies
- tune the alpha parameter for the policies that work in epochs
